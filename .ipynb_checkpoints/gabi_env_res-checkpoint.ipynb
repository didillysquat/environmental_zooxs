{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gabi's env_res project\n",
    "This notebook will document the processing of the data for Gabi's MSc. project that was collected some time ago by Maren.\n",
    "The samples that were collected were supposed to be used to characterise the zooxs present before during and after a bleaching episode but the bleaching never happened and so the sample collection was somewhat abandoned. The samples will now be repurposed and used by Gabi for her MSc project. The object of which will be to compare the diversity of ITS2 sequences found in the corals to those found in the environmental samples.\n",
    "\n",
    "Originally, we had planned to look for ITS2 profiles found in the coral samples in the environmental samples. I spent a lot of time writing code to search for the ITS2 type profiles but in the end this approach was abandoned because we did have a big enough selection of corals to really capture the full diversity of DIV abundances. As such we weren't finding many of the profiles in the environmental samples. \n",
    "\n",
    "Instead of this approach we will now aim for a much more simplified approach which will purely look at the diversities of ITS2 sequences in the coral samples and compare this to the diverstiy of sequences found in the environmental samples.\n",
    "\n",
    "As mentioned above there was originally a time component to the original samples collected. You will see in the info file that there are different collection dates. We will not be using any of these time replicate samples and only using the samples that werwe colleceted at the same time as the first batch of corals. You will also see that there were an additional set of corals that were collected at a second date and did not have a plot number associated with them. These will also be discarded.\n",
    "\n",
    "There was also a spatial consideration to the original data collection with there being 5 plots and the aim was to see whether environmental resevoirs were more specific to coral samples between and among the plots. However, due to the minimal number of environmental samples we are not able to take into account this aspect of the study so the plot factor will be ignored. \n",
    "\n",
    "You will see that that leaves us with a total of about 50 corals (although several sponge samples need to be removed) and associated mucus samples, 5 water samples, 5 close sediment samples (sampled at the base of the coral shelf), 5 far sediment samples (sampled 2m from the base of the coral shelf), and 10 turf algae samples.\n",
    "\n",
    "#### Sections\n",
    "* [Clean up data input](#Clean-up-data-input)\n",
    "* [Python code processing](#Python-code-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up data input\n",
    "\n",
    "One of the first things to deal with is the info data that contains the metadata for the samples. This was in the form of an excel file that has some formating issues when exported in .csv (as always). We will clean that up below. * We can't type the ^M special character here so I will just say that we ran ```$sed 's/[,]+^M$//g' info_290819.csv > info_290819.csv```\n",
    "\n",
    "We have the SP outputs in this directory, the info.csv that needs cleaning up and the code for generating the figs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head info_290819.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head info_290819_fix.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sed '/^\\s*$/d' info_290819_fix.csv > info_290819_fix_fix.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head info_290819_fix_fix.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail info_290819_fix_fix.csv | cat -A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sed -r 's/^,+$//g' info_290819_fix_fix.csv > info_290819_fix_fix_fix.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail info_290819_fix_fix_fix.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv info_290819_fix_fix_fix.csv info_300718.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm *2908*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "info_300718.csv is now our meta datafile that we will work with in the python processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head info_300718.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python code processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Read in the info file and the SP output file__\n",
    "\n",
    "Then clean these up by dropping the samples that are not of the correct data. Then relate the SP output and info files so that they have the same names for the samples. Also pickle out the data_frames and have a check to see if they already exist.\n",
    "\n",
    "The warning spat out by pandas can be ignored in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    sp_output_df = pickle.load(open('sp_output_df.pickle', 'rb'))\n",
    "    QC_info_df= pickle.load(open('QC_info_df.pickle', 'rb'))\n",
    "    info_df = pickle.load(open('info_df.pickle', 'rb'))\n",
    "except:\n",
    "    # read in the SymPortal output\n",
    "    sp_output_df = pd.read_csv('131_142.DIVs.absolute.txt', sep='\\t', lineterminator='\\n')\n",
    "\n",
    "    # The SP output contains the QC info columns between the DIVs and the no_name ITS2 columns.\n",
    "    # lets put the QC info columns into a seperate df.\n",
    "    QC_info_df = sp_output_df[['Samples','raw_contigs', 'post_qc_absolute_seqs', 'post_qc_unique_seqs',\n",
    "                            'post_taxa_id_absolute_symbiodinium_seqs', 'post_taxa_id_unique_symbiodinium_seqs',\n",
    "                            'post_taxa_id_absolute_non_symbiodinium_seqs', 'post_taxa_id_unique_non_symbiodinium_seqs',\n",
    "                               'size_screening_violation_absolute', 'size_screening_violation_unique',\n",
    "                               'post_med_absolute', 'post_med_unique']]\n",
    "\n",
    "    # now lets drop the QC columns from the SP output df and also drop the clade summation columns\n",
    "    # we will be left with just clumns for each one of the sequences found in the samples\n",
    "    sp_output_df.drop(columns=['noName Clade A', 'noName Clade B', 'noName Clade C', 'noName Clade D',\n",
    "                            'noName Clade E', 'noName Clade F', 'noName Clade G', 'noName Clade H',\n",
    "                            'noName Clade I', 'raw_contigs', 'post_qc_absolute_seqs', 'post_qc_unique_seqs',\n",
    "                            'post_taxa_id_absolute_symbiodinium_seqs', 'post_taxa_id_unique_symbiodinium_seqs',\n",
    "                            'post_taxa_id_absolute_non_symbiodinium_seqs', 'post_taxa_id_unique_non_symbiodinium_seqs',\n",
    "                               'size_screening_violation_absolute', 'size_screening_violation_unique',\n",
    "                               'post_med_absolute', 'post_med_unique'\n",
    "                               ]\n",
    "                      , inplace=True)\n",
    "\n",
    "    # read in the info file\n",
    "    info_df = pd.read_csv('info_300718.csv')\n",
    "\n",
    "    # drop the rows that aren't from the 22.08.2016 data\n",
    "    info_df = info_df[info_df['date collected'] == '22.08.2016']\n",
    "\n",
    "    # Now we need to link the SP output to the sample names in the excel. Annoyingly they are formatted\n",
    "    # slightly differently so we can't make a direct comparison.\n",
    "    # easiest way to link them is to see if the first part of the SP name is the same as the first part\n",
    "    # of the 'sequence file' in the meta info\n",
    "    # when doing this we can also drop the SP info for those samples that won't be used i.e. those that\n",
    "    # aren't now in the info_df\n",
    "\n",
    "    # firstly rename the colums so that they are 'sample_name' in all of the dfs\n",
    "    QC_info_df.rename(index=str, columns={'Samples': 'sample_name'}, inplace=True)\n",
    "    sp_output_df.rename(index=str, columns={'Samples': 'sample_name'}, inplace=True)\n",
    "    info_df.rename(index=str, columns={'Sample Name': 'sample_name'}, inplace=True)\n",
    "\n",
    "    indices_to_drop = []\n",
    "    for sp_index in sp_output_df.index.values.tolist():\n",
    "        # keep track of whether the sp_index was found in the info table\n",
    "        # if it wasn't then it should be dropped\n",
    "        found = False\n",
    "        for info_index in info_df.index.values.tolist():\n",
    "            if sp_output_df.loc[sp_index, 'sample_name'].split('_')[0] == info_df.loc[info_index, 'Sequence file'].split('_')[0]:\n",
    "                found = True\n",
    "                # then these are a related set of rows and we should make the sample_names the same\n",
    "                sp_output_df.loc[sp_index, 'sample_name'] = info_df.loc[info_index, 'sample_name']\n",
    "                QC_info_df.loc[sp_index, 'sample_name'] = info_df.loc[info_index, 'sample_name']\n",
    "\n",
    "\n",
    "        if not found:\n",
    "            indices_to_drop.append(sp_index)\n",
    "\n",
    "    # drop the rows from the SP output tables that aren't going to be used\n",
    "    sp_output_df.drop(inplace=True, index=indices_to_drop)\n",
    "    QC_info_df.drop(inplace=True, index=indices_to_drop)\n",
    "\n",
    "    # let's sort out the 'environ type' column in the info_df\n",
    "    # currently it is a bit of a mess\n",
    "    for index in info_df.index.values.tolist():\n",
    "        if 'coral' in info_df.loc[index, 'Sample no.']:\n",
    "            info_df.loc[index, 'environ type'] = 'coral'\n",
    "        elif 'seawater' in info_df.loc[index, 'Sample no.']:\n",
    "            info_df.loc[index, 'environ type'] = 'sea_water'\n",
    "        elif 'mucus' in info_df.loc[index, 'Sample no.']:\n",
    "            info_df.loc[index, 'environ type'] = 'mucus'\n",
    "        elif 'SA' in info_df.loc[index, 'Sample no.']:\n",
    "            info_df.loc[index, 'environ type'] = 'sed_close'\n",
    "        elif 'SB' in info_df.loc[index, 'Sample no.']:\n",
    "            info_df.loc[index, 'environ type'] = 'sed_far'\n",
    "        elif 'TA' in info_df.loc[index, 'Sample no.']:\n",
    "            info_df.loc[index, 'environ type'] = 'turf'\n",
    "\n",
    "    # now clean up the df indices\n",
    "    info_df.index = range(len(info_df))\n",
    "    sp_output_df.index = range(len(sp_output_df))\n",
    "    QC_info_df.index = range(len(QC_info_df))\n",
    "\n",
    "    # make the sample_name column the index for each of the datasets\n",
    "    info_df.set_index('sample_name', inplace=True)\n",
    "    sp_output_df.set_index('sample_name', inplace=True)\n",
    "    QC_info_df.set_index('sample_name', inplace=True)\n",
    "\n",
    "    # pickle the out put and put a check in place to see if we need to do the above\n",
    "    pickle.dump(sp_output_df, open('sp_output_df.pickle', 'wb'))\n",
    "    pickle.dump(QC_info_df, open('QC_info_df.pickle', 'wb'))\n",
    "    pickle.dump(info_df, open('info_df.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(QC_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq_rel_abund_calculator_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create dictionary that will contain seq_name as key, value = tuple of (sample name with highest abundnce of the sequence, the rel abundance of the sequence)__\n",
    "\n",
    "See comments in code for further explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we want to plot the ITS2 sequence diversity in each of the samples as bar charts\n",
    "# We are going to have a huge diversity of sequences to deal with so I think something along the lines\n",
    "# of plotting the top n most abundant sequences. The term 'most abundant' should be considered carefully here\n",
    "# I think it will be best if we work on a sample by sample basis. i.e. we pick the n sequences that have the\n",
    "# highest representation in any one sample. So for example what we are not doing is seeing how many times\n",
    "# C3 was sequenced across all of the samples, and finding that it is a lot and therefore plotting it.\n",
    "# we are looking in each of the samples and seeing the highest proportion it is found at in any one sample.\n",
    "# This way we should have the best chance of having a coloured representation for each sample's most abundant\n",
    "# sequence.\n",
    "\n",
    "# to start lets go sample by sample and see what the highest prop for each seq is.\n",
    "\n",
    "# dict to hold info on which sample and what the proportion is for each sequence\n",
    "# key = sequence name, value = tup ( sample name, relative abundance)\n",
    "try:\n",
    "    seq_rel_abund_calculator_dict = pickle.load(open('seq_rel_abund_calculator_dict.pickle', 'rb'))\n",
    "except:\n",
    "    seq_rel_abund_calculator_dict = {}\n",
    "    for sample_index in sp_output_df.index.values.tolist():\n",
    "        sys.stdout.write('\\nGeting rel seq abundances from {}\\n'.format(sample_index))\n",
    "        # temp_prop_array = sp_output_df.loc[sample_index].div(sp_output_df.loc[sample_index].sum(axis='index'))\n",
    "        temp_prop_array = sp_output_df.loc[sample_index].div(sp_output_df.loc[sample_index].sum())\n",
    "        for seq_name in temp_prop_array.keys():\n",
    "            sys.stdout.write('\\rseq: {}'.format(seq_name))\n",
    "            val = temp_prop_array[seq_name]\n",
    "            if val != 0:  # if the sequences was found in the sample\n",
    "                # If the sequence is already in the dict\n",
    "                if seq_name in seq_rel_abund_calculator_dict.keys():\n",
    "                    # check to seee if the rel abundance is larger than the one already logged\n",
    "                    if val > seq_rel_abund_calculator_dict[seq_name][1]:\n",
    "                        seq_rel_abund_calculator_dict[seq_name] = (sample_index, val)\n",
    "                # if we haven't logged for this sequence yet, then add this as the first log\n",
    "                else:\n",
    "                    seq_rel_abund_calculator_dict[seq_name] = (sample_index, val)\n",
    "    pickle.dump(seq_rel_abund_calculator_dict, open('seq_rel_abund_calculator_dict.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a sorted list of sequences where the first sequence has the highest rel abundance in any one given sample__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have a dict that contains the largest rel_abundances per sample for each of the seqs\n",
    "# now we can sort this to look at the top ? n sequences to start with (I'm not sure how the colouring will\n",
    "# look like so lets just start with 30 and see where we get to)\n",
    "sorted_list = sorted(seq_rel_abund_calculator_dict.items(), key = lambda x: x[1][1], reverse=True)\n",
    "most_abund_seq_names = [tup[0] for tup in sorted_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__From this list create a colour dictionary which will hold the info for which sequences should be which colour and will keep the colours consistent between each of the subplots__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colour_list():\n",
    "    colour_list = [\"#FFFF00\", \"#1CE6FF\", \"#FF34FF\", \"#FF4A46\", \"#008941\", \"#006FA6\", \"#A30059\", \"#FFDBE5\",\n",
    "                  \"#7A4900\", \"#0000A6\", \"#63FFAC\", \"#B79762\", \"#004D43\", \"#8FB0FF\", \"#997D87\", \"#5A0007\", \"#809693\",\n",
    "                  \"#FEFFE6\", \"#1B4400\", \"#4FC601\", \"#3B5DFF\", \"#4A3B53\", \"#FF2F80\", \"#61615A\", \"#BA0900\", \"#6B7900\",\n",
    "                  \"#00C2A0\", \"#FFAA92\", \"#FF90C9\", \"#B903AA\", \"#D16100\", \"#DDEFFF\", \"#000035\", \"#7B4F4B\", \"#A1C299\",\n",
    "                  \"#300018\", \"#0AA6D8\", \"#013349\", \"#00846F\", \"#372101\", \"#FFB500\", \"#C2FFED\", \"#A079BF\", \"#CC0744\",\n",
    "                  \"#C0B9B2\", \"#C2FF99\", \"#001E09\", \"#00489C\", \"#6F0062\", \"#0CBD66\", \"#EEC3FF\", \"#456D75\", \"#B77B68\",\n",
    "                  \"#7A87A1\", \"#788D66\", \"#885578\", \"#FAD09F\", \"#FF8A9A\", \"#D157A0\", \"#BEC459\", \"#456648\", \"#0086ED\",\n",
    "                  \"#886F4C\", \"#34362D\", \"#B4A8BD\", \"#00A6AA\", \"#452C2C\", \"#636375\", \"#A3C8C9\", \"#FF913F\", \"#938A81\",\n",
    "                  \"#575329\", \"#00FECF\", \"#B05B6F\", \"#8CD0FF\", \"#3B9700\", \"#04F757\", \"#C8A1A1\", \"#1E6E00\", \"#7900D7\",\n",
    "                  \"#A77500\", \"#6367A9\", \"#A05837\", \"#6B002C\", \"#772600\", \"#D790FF\", \"#9B9700\", \"#549E79\", \"#FFF69F\",\n",
    "                  \"#201625\", \"#72418F\", \"#BC23FF\", \"#99ADC0\", \"#3A2465\", \"#922329\", \"#5B4534\", \"#FDE8DC\", \"#404E55\",\n",
    "                  \"#0089A3\", \"#CB7E98\", \"#A4E804\", \"#324E72\", \"#6A3A4C\", \"#83AB58\", \"#001C1E\", \"#D1F7CE\", \"#004B28\",\n",
    "                  \"#C8D0F6\", \"#A3A489\", \"#806C66\", \"#222800\", \"#BF5650\", \"#E83000\", \"#66796D\", \"#DA007C\", \"#FF1A59\",\n",
    "                  \"#8ADBB4\", \"#1E0200\", \"#5B4E51\", \"#C895C5\", \"#320033\", \"#FF6832\", \"#66E1D3\", \"#CFCDAC\", \"#D0AC94\",\n",
    "                  \"#7ED379\", \"#012C58\", \"#7A7BFF\", \"#D68E01\", \"#353339\", \"#78AFA1\", \"#FEB2C6\", \"#75797C\", \"#837393\",\n",
    "                  \"#943A4D\", \"#B5F4FF\", \"#D2DCD5\", \"#9556BD\", \"#6A714A\", \"#001325\", \"#02525F\", \"#0AA3F7\", \"#E98176\",\n",
    "                  \"#DBD5DD\", \"#5EBCD1\", \"#3D4F44\", \"#7E6405\", \"#02684E\", \"#962B75\", \"#8D8546\", \"#9695C5\", \"#E773CE\",\n",
    "                  \"#D86A78\", \"#3E89BE\", \"#CA834E\", \"#518A87\", \"#5B113C\", \"#55813B\", \"#E704C4\", \"#00005F\", \"#A97399\",\n",
    "                  \"#4B8160\", \"#59738A\", \"#FF5DA7\", \"#F7C9BF\", \"#643127\", \"#513A01\", \"#6B94AA\", \"#51A058\", \"#A45B02\",\n",
    "                  \"#1D1702\", \"#E20027\", \"#E7AB63\", \"#4C6001\", \"#9C6966\", \"#64547B\", \"#97979E\", \"#006A66\", \"#391406\",\n",
    "                  \"#F4D749\", \"#0045D2\", \"#006C31\", \"#DDB6D0\", \"#7C6571\", \"#9FB2A4\", \"#00D891\", \"#15A08A\", \"#BC65E9\",\n",
    "                  \"#FFFFFE\", \"#C6DC99\", \"#203B3C\", \"#671190\", \"#6B3A64\", \"#F5E1FF\", \"#FFA0F2\", \"#CCAA35\", \"#374527\",\n",
    "                  \"#8BB400\", \"#797868\", \"#C6005A\", \"#3B000A\", \"#C86240\", \"#29607C\", \"#402334\", \"#7D5A44\", \"#CCB87C\",\n",
    "                  \"#B88183\", \"#AA5199\", \"#B5D6C3\", \"#A38469\", \"#9F94F0\", \"#A74571\", \"#B894A6\", \"#71BB8C\", \"#00B433\",\n",
    "                  \"#789EC9\", \"#6D80BA\", \"#953F00\", \"#5EFF03\", \"#E4FFFC\", \"#1BE177\", \"#BCB1E5\", \"#76912F\", \"#003109\",\n",
    "                  \"#0060CD\", \"#D20096\", \"#895563\", \"#29201D\", \"#5B3213\", \"#A76F42\", \"#89412E\", \"#1A3A2A\", \"#494B5A\",\n",
    "                  \"#A88C85\", \"#F4ABAA\", \"#A3F3AB\", \"#00C6C8\", \"#EA8B66\", \"#958A9F\", \"#BDC9D2\", \"#9FA064\", \"#BE4700\",\n",
    "                  \"#658188\", \"#83A485\", \"#453C23\", \"#47675D\", \"#3A3F00\", \"#061203\", \"#DFFB71\", \"#868E7E\", \"#98D058\",\n",
    "                  \"#6C8F7D\", \"#D7BFC2\", \"#3C3E6E\", \"#D83D66\", \"#2F5D9B\", \"#6C5E46\", \"#D25B88\", \"#5B656C\", \"#00B57F\",\n",
    "                  \"#545C46\", \"#866097\", \"#365D25\", \"#252F99\", \"#00CCFF\", \"#674E60\", \"#FC009C\", \"#92896B\"]\n",
    "    return colour_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the above sorted list we can then plot these sequences with colour and all others with grey scale\n",
    "# lets make a coulour dictionary for the most common types\n",
    "colour_list = get_colour_list()\n",
    "colour_dict = {}\n",
    "num_coloured_seqs = 30\n",
    "\n",
    "# we will also need a grey palette for those sequences that are not the ones being annotated\n",
    "grey_palette = ['#D0CFD4', '#89888D', '#4A4A4C', '#8A8C82', '#D4D5D0', '#53544F']\n",
    "\n",
    "# make the dict\n",
    "for i in range(len(most_abund_seq_names)):\n",
    "    if i < num_coloured_seqs:\n",
    "        colour_dict[most_abund_seq_names[i]] = colour_list[i]\n",
    "    else:\n",
    "        colour_dict[most_abund_seq_names[i]] = grey_palette[i % 6]\n",
    "# add the 'low' key and assign it to grey for later on\n",
    "# the low category will be created later on to hold the grouped abundances of sequences in samples\n",
    "# below a certain rel abund cutoff\n",
    "colour_dict['low'] = '#D0CFD4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set up the structures for collecting the rectangle objects we will use for making the legend later on__\n",
    "\n",
    "See comments in the code for further details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting we will also need to collect the 'rectangle' objects from the plotting process to use to make\n",
    "# the lengend which we will display on the plot right at the end\n",
    "# this is going to be a little tricky to collect as not ever sample type group that we are plotting\n",
    "# is going to have all of the top n sequences. So, we will have to pick up rectangles when they come up in\n",
    "# the plotting.\n",
    "# to keep track of which sequences we need we have:\n",
    "top_n_seqs_to_get = most_abund_seq_names[:num_coloured_seqs]\n",
    "# to keep track of which sequences we have already collected we have:\n",
    "top_n_seqs_done = []\n",
    "#finally to collect the rectangles and store them in order despite collecting them out of order we have:\n",
    "legend_rectangle_holder = [[] for i in range(num_coloured_seqs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Setup the figure as a set of sub plots, one for each of the sample types__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Do the plotting sample type by sample type__\n",
    "\n",
    "This will also involve collecting all of the information for plotting. We will do a little bit of processing here whereby we will group all sequences below a given rel abun cut off into a group called 'low'. If we don't do this then we simply end up with too many sequences to plot and work with. I think I am currently running with a rel_abund cutoff of 0.005 which is already pretty low. This leaves us with ~200 sequences to plot for the coral samples, a lot less for the other sample types e.g. turf.\n",
    "\n",
    "Normally I would make a 2D list that I would collect the plotting information in but in this case we will make a dataframe taht will only hold the information for the sample type in question.\n",
    "\n",
    "Because this code in in a for loop it will be a lot of code in one go but hopefully the comments are good enough to see what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating plotting info for coral samples\n",
      "196/197\n",
      "Generating plotting info for mucus samples\n",
      "190/191\n",
      "Generating plotting info for sea_water samples\n",
      "58/595\n",
      "Generating plotting info for sed_close samples\n",
      "87/889\n",
      "Generating plotting info for sed_far samples\n",
      "80/810\n",
      "Generating plotting info for turf samples\n",
      "72/730"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set up the plotting environment\n",
    "# one plot for coral, mucus, seawater, sediment, turf_algae\n",
    "f, axarr = plt.subplots(6, 1)\n",
    "# counter to reference which set of axes we are plotting on\n",
    "axarr_index = 0\n",
    "\n",
    "# now we need to get the actual plotting information for each of the samples.\n",
    "# we can do this sample type by sample type\n",
    "# we will create a local dataframe that will be a sub set of the main sp output dataframe but will\n",
    "# only contain the samples of the given sample type. It will also eventually only contain the sequence\n",
    "# information for the sample type in question. Normally I would make a 2D list to hold the plotting\n",
    "# information but in this case having all of the informatin in a dataframe is working really well and\n",
    "# this is how I will do it in future.\n",
    "\n",
    "# go environment type by environment type\n",
    "for env_type in ['coral', 'mucus', 'sea_water', 'sed_close', 'sed_far', 'turf']:\n",
    "    sys.stdout.write('\\nGenerating plotting info for {} samples\\n'.format(env_type))\n",
    "    # currently we have something like 4000 sequences to plot which is too may\n",
    "    # I think it will be much easier if we group the sequences that are found below a certain\n",
    "    # threshold. I think the best way to do this is to create a slice of the main df that\n",
    "    # contain the information for the samples of the env_type only\n",
    "\n",
    "    # get subset of the main dfs that contain only the coral samples\n",
    "    env_info_df = info_df[info_df['environ type'] == env_type]\n",
    "    env_sp_output_df = sp_output_df.loc[env_info_df.index.values.tolist()]\n",
    "\n",
    "    # append a 'low' columns to the env_sp_ouput_df and populate with 0s\n",
    "    env_sp_output_df['low'] = 0\n",
    "    # now make a proportions version of the df, rather than absolute counts\n",
    "    env_sp_output_df_prop = env_sp_output_df[:].div(env_sp_output_df[:].sum(axis=1), axis=0)\n",
    "\n",
    "    # now as we work our way through we can sum up the low sequences into this column\n",
    "    # we can then check for 0 columns and drop these.\n",
    "\n",
    "    # get a list of the sequences found in the collection of samples of the given type and order\n",
    "    # them according to summed rel_abundance acorss all samples. This should be the order in which\n",
    "    # the samples are plotted\n",
    "    # at the same time we can get the info we need for plotting\n",
    "\n",
    "    summed_seq_rel_abund_across_smpls_dict = {seq: 0 for seq in list(sp_output_df)}\n",
    "\n",
    "    # we are also going to need to put the samples in an order that makes sense.\n",
    "    # Ideally I would like to take the time to do a proper travelling salesman analysis\n",
    "    # and I was thinking of putting in an ant colony system to do this but...\n",
    "    # I'm not sure we've got time for that. So let's do something a little more simple which\n",
    "    # should still be effective and look groovy\n",
    "    # Lets sort according to the majority sequence. I.e. lets put the samples into groups that\n",
    "    # are defined by what their majorty sequence is, then lets plot in order of those groups.\n",
    "    # within the groups we will plot in the order of the most abundant rel abund first.\n",
    "    # to get this information we will have a dict to collect it. The key of the dict will\n",
    "    # be the majority sequence with the value being a list that contains tuples. One tuple\n",
    "    # for each sample in the list which will contain the sample_name and the re abund of the maj seq\n",
    "\n",
    "    # Dict for holding the sample_sorting info\n",
    "    sample_sorting_info_dict = defaultdict(list)\n",
    "\n",
    "    for sp_index in env_sp_output_df_prop.index.values.tolist():\n",
    "        sys.stdout.write('\\r{}'.format(sp_index))\n",
    "        # we need to get the name of the most abundant sequence and its rel abund for each sample\n",
    "        # for the sample_sorting_info_dict\n",
    "        most_abund_seq_name = env_sp_output_df_prop.loc[sp_index].idxmax(axis='index')\n",
    "        rel_abund_of_most_abund_seq = env_sp_output_df_prop.loc[sp_index, most_abund_seq_name]\n",
    "        sample_sorting_info_dict[most_abund_seq_name].append((sp_index, rel_abund_of_most_abund_seq))\n",
    "        # Put its seq rel abundances ino the summed_seq_rel_abund_across... dict\n",
    "\n",
    "        for non_zero_seq in env_sp_output_df_prop.loc[sp_index][env_sp_output_df_prop.loc[sp_index] > 0].index:  # not including the final 'low' columns (this will be zero)\n",
    "            val = env_sp_output_df_prop.loc[sp_index, non_zero_seq]\n",
    "            # be sure to count the value of this cell and using it in judging which are the most\n",
    "            # abundant sequences before we check whether to relegate it to the 'low' column\n",
    "            summed_seq_rel_abund_across_smpls_dict[non_zero_seq] += val\n",
    "            if val < 0.005:\n",
    "                env_sp_output_df_prop.loc[sp_index, 'low'] += val\n",
    "                env_sp_output_df_prop.loc[sp_index, non_zero_seq] = 0\n",
    "\n",
    "\n",
    "    # here we can get a sorted sample list using the sample_sorting_info_dict\n",
    "    sorted_sample_list = []\n",
    "    # we want to work through the sample_sorting_info_dict by the longest lists first\n",
    "    sorted_keys_for_sample_sort = \\\n",
    "        [tup[0] for tup in sorted(sample_sorting_info_dict.items(), key=lambda x: len(x[1]), reverse=True)]\n",
    "    # for each of teh maj seq groups\n",
    "    for sorted_key in sorted_keys_for_sample_sort:\n",
    "        # now within each of these lists we want to order according to the rel_abundance of the sequences\n",
    "        sorted_list_of_samples_of_group = [tup[0] for tup in sorted(sample_sorting_info_dict[sorted_key], key=lambda x: x[1], reverse=True)]\n",
    "        sorted_sample_list.extend(sorted_list_of_samples_of_group)\n",
    "\n",
    "    # now we should re-order the df so that it is in the sample order of sorted_sample_list\n",
    "    env_sp_output_df_prop = env_sp_output_df_prop.reindex(sorted_sample_list)\n",
    "\n",
    "    # here we have a dict that contains the abundances of the seqs for the coral samples\n",
    "    # we will plot the coral samples' seqs in the order of the sequences in this dict\n",
    "    sorted_list_of_env_specific_seqs_tup \\\n",
    "        = sorted(summed_seq_rel_abund_across_smpls_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_list_of_env_specific_seqs = [tup[0] for tup in sorted_list_of_env_specific_seqs_tup]\n",
    "\n",
    "    # Now we check for zero only columns and drop them\n",
    "    # we also need to remove these columns from the sorted\n",
    "    non_zero_cols = list(env_sp_output_df_prop.loc[:, (env_sp_output_df_prop != 0).any(axis=0)])\n",
    "    sorted_list_of_env_specific_seqs = [seq for seq in sorted_list_of_env_specific_seqs if seq in non_zero_cols]\n",
    "\n",
    "    # add the 'low' column\n",
    "    sorted_list_of_env_specific_seqs.append('low')\n",
    "\n",
    "    # now drop the cols\n",
    "    env_sp_output_df_prop = env_sp_output_df_prop[non_zero_cols]\n",
    "\n",
    "    # we also have the plotting list which contains the info we will be plotting.\n",
    "\n",
    "    # the plotting_list is currently organised in a different order to that of the sorted_list_of_env...\n",
    "    # we need to change this order\n",
    "    env_sp_output_df_prop = env_sp_output_df_prop[sorted_list_of_env_specific_seqs]\n",
    "\n",
    "    # we now need to transpose this\n",
    "    env_sp_output_df_prop = env_sp_output_df_prop.transpose()\n",
    "\n",
    "    # here we finally have the plotting lists in the order of the sorted_list_of_env\n",
    "    bottom = [0 for smp in list(env_sp_output_df_prop)]\n",
    "    bar_list = []\n",
    "    # for each sample\n",
    "    plotting_indices = range(len(list(env_sp_output_df_prop)))\n",
    "\n",
    "    # for each sequence\n",
    "    list_of_seqs = env_sp_output_df_prop.index.values.tolist()\n",
    "    for i in range(len(list_of_seqs)):\n",
    "\n",
    "        sys.stdout.write('\\r{}/{}'.format(i, len(list(env_sp_output_df_prop.iloc[:, 0]))))\n",
    "        bar_list.append(axarr[axarr_index].bar(plotting_indices, list(env_sp_output_df_prop.iloc[i]), 1, bottom,\n",
    "                                               color=colour_dict[sorted_list_of_env_specific_seqs[i]]))\n",
    "        bottom = [L + M for L, M in zip(bottom, list(env_sp_output_df_prop.iloc[i]))]\n",
    "\n",
    "        # check to see if the seq we are plotting is still in the top_n_seqs list\n",
    "        # if it is in this list then we still need to grab a rectangle for plotting\n",
    "        # the legend. Once we have grabbed the rectangle then we should remove the seq from the top_n_seqs list\n",
    "        seq_name = list_of_seqs[i]\n",
    "        top_n_seqs_done = []\n",
    "        if seq_name in top_n_seqs_to_get and seq_name not in top_n_seqs_done:\n",
    "            # then this is a seq that we still need to get a rectangle for the legend\n",
    "            legend_rectangle_holder[top_n_seqs_to_get.index(seq_name)].append(bar_list[-1][0])\n",
    "            top_n_seqs_done.append(seq_name)\n",
    "\n",
    "    # https://stackoverflow.com/questions/12998430/remove-xticks-in-a-matplotlib-plot\n",
    "    axarr[axarr_index].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    # https://stackoverflow.com/questions/15858192/how-to-set-xlim-and-ylim-for-a-subplot-in-matplotlib\n",
    "    axarr[axarr_index].set_xlim((-0.5, (len(list(env_sp_output_df_prop)) - 0.5)))\n",
    "    # https://stackoverflow.com/questions/925024/how-can-i-remove-the-top-and-right-axis-in-matplotlib\n",
    "    axarr[axarr_index].spines['right'].set_visible(False)\n",
    "    axarr[axarr_index].spines['top'].set_visible(False)\n",
    "\n",
    "    # To make the legend for this mo fo is going to be a little tricky. The legend argument basically takes\n",
    "    # two lists. The first list should contain a rectangle object for each of the sequences (this\n",
    "    # will be the coloured box). We get this object from the bar objects that we are creating.\n",
    "    # The second list is a list of the labels. This should be easier. We can just use the\n",
    "    # most_abund_seq_names[:30] for these.\n",
    "    # to grab the rectangles, I think its best to pick them up during the plotting and hold them in a list\n",
    "    # outside of the subplot loop. We will need a holder for the objects to populate.\n",
    "\n",
    "    #https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_xticks.html#matplotlib.axes.Axes.set_xticks\n",
    "    axarr[axarr_index].set_yticks([1], minor=False)\n",
    "    #https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_xticklabels.html#matplotlib.axes.Axes.set_xticklabels\n",
    "    axarr[axarr_index].set_yticklabels(['1'])\n",
    "    axarr[axarr_index].set_xlabel(env_type)\n",
    "\n",
    "\n",
    "\n",
    "    axarr_index += 1\n",
    "\n",
    "#https://stackoverflow.com/questions/16150819/common-xlabel-ylabel-for-matplotlib-subplots/26892326\n",
    "f.text(0, 0.5, 'ITS2 sequence relative abundance', va='center', rotation='vertical')\n",
    "ordered_rectange_list = [sub_list[0] for sub_list in legend_rectangle_holder]\n",
    "# Uncomment when running locally to make the actual figure\n",
    "# f.legend(ordered_rectange_list, top_n_seqs_to_get, loc='lower center')\n",
    "\n",
    "plt.tight_layout()\n",
    "f.savefig('diversity_bars.svg')\n",
    "#Uncomment for running in local environment. Causes a crash in Jupyter\n",
    "#f.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
